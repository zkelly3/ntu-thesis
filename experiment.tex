\chapter{實驗設定與結果}
\label{c:experiment}

在這一章中，我們會先介紹我們在實驗中所使用到的資料集，然後說明我們在訓練和測試時使用的設定與參數，接著展示我們進行測試所獲得在數據與視覺上的結果，最後展示對我們的方法進行消熔實驗的結果與討論。

\section{資料集}

我們在實驗中所使用到的資料集主要分為訓練用和測試用的資料集。

\begin{figure}[t]
\centering
\begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{figures/wider_1}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{figures/wider_2}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{figures/wider_3}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{figures/wider_4}
\end{subfigure}
\begin{subfigure}[b]{0.3\textwidth}
    \includegraphics[width=\textwidth]{figures/same_original}
\end{subfigure}
\caption[Wider Face 資料集中的圖片範例]{Wider Face 資料集收集了各種不同情境下的人臉}
\label{fig:wider_face}
\end{figure}

訓練時我們使用了 Wider Face~\cite{yang2016wider} 作為主要的資料集。它是一個人臉資料集，其收集了各種不同情境下的人臉 (如圖~\ref{fig:wider_face})，共計 32,203 張圖片、393,703 張人臉，在人臉偵測這個議題上是很經典的資料集。在我們的實驗中，我們將資料集中的圖片分別做了曝光不足和曝光過度的模擬。其中曝光不足的模擬將圖片亮度隨機調為 3\%、5\%、7\%，並將每張圖隨機分配 1 \textasciitilde 10 的數字$n$，以$\sigma = n$的設定對每張圖做高斯雜訊；曝光過度的模擬則將圖片亮度隨機調為 100\%、250\%、400\%。

\begin{figure}[t]
\centering
\begin{subfigure}[b]{0.22\textwidth}
    \includegraphics[width=\textwidth]{figures/test_1_1}
\end{subfigure}
\begin{subfigure}[b]{0.22\textwidth}
    \includegraphics[width=\textwidth]{figures/test_2_1}
\end{subfigure}
\begin{subfigure}[b]{0.22\textwidth}
    \includegraphics[width=\textwidth]{figures/test_3_1}
\end{subfigure}
\begin{subfigure}[b]{0.22\textwidth}
    \includegraphics[width=\textwidth]{figures/test_4_1}
\end{subfigure}
\begin{subfigure}[b]{0.22\textwidth}
    \includegraphics[width=\textwidth]{figures/test_1_2}
    \caption {白天進出隧道}
\end{subfigure}
\begin{subfigure}[b]{0.22\textwidth}
    \includegraphics[width=\textwidth]{figures/test_2_2}
    \caption {夜間極暗}
\end{subfigure}
\begin{subfigure}[b]{0.22\textwidth}
    \includegraphics[width=\textwidth]{figures/test_3_2}
    \caption {夜間等紅燈}
\end{subfigure}
\begin{subfigure}[b]{0.22\textwidth}
    \includegraphics[width=\textwidth]{figures/test_4_2}
    \caption {夜間隧道內}
\end{subfigure}
\caption[測試資料集中的圖片範例]{測試資料集中包含白天進出隧道、夜間極暗、夜間等紅燈和夜間隧道內四個情境}
\label{fig:test_data}
\end{figure}

測試時我們則使用了自己拍攝的車內影像和人工標註的偵測框。我們在進行拍攝時將 Patriot F5 置於前擋風玻璃右上角，影像解析度為$1280 \times 720$，幀率為 30 fps。影像中會出現三個人，包含駕駛、副駕駛、後座的乘客。標註時我們採用和訓練時所使用的 Wider Face 資料集相同的定義，使偵測框緊貼臉部的前額、下巴和臉頰。
此資料集有以下四個情境：白天進出隧道 900 張、夜間極暗 900 張、夜間等紅燈 900 張、夜間隧道內 1000 張 (如圖~\ref{fig:test_data})。白天進出隧道是四個情境中最亮的，用來測試進出隧道時的光線劇烈變化造成的影響；夜間極暗是一個環境光非常微弱的情境，用來測試缺乏環境光造成的影響；夜間等紅燈是一個會受到紅燈直接照射的情境，用來測試資料有色差造成的影響；夜間隧道內是一個隧道光源較微弱的情境，用來測試環境光僅能照亮部分影像造成的影響。在後續的實驗我們也會將這四個情境分開測試。
為求說明方便，後續提到資料集時會使用表~\ref{table:model_names}中對資料集的命名。
\begin{table}[ht]
    \caption{對不同資料集的命名}
    \centering
    \begin{tabular}{l l l}
        \hline
        資料集名稱 & 說明 & 使用時機 \\
        \hline
        $D_{Original}$ & Wider Face 的原始資料集 & - \\
        $D_{Dark}$ & 將 $D_{Original}$ 做曝光不足模擬後的資料集 & - \\
        $D_{Bright}$ & 將 $D_{Original}$ 做曝光過度模擬後的資料集 & - \\
        $D_{Triple}$ & 包含 $D_{Original}$、$D_{Dark}$、$D_{Bright}$ 三個資料集 & 預訓練 \\
        $D_{Train}$	& 包含 $D_{Dark}$ 和 $D_{Bright}$ 兩個資料集 & 主要訓練 \\
        $D_{Test}$ & 我們拍攝的車內影像 & 測試 \\
        \hline
    \end{tabular}
    \label{table:model_names}
\end{table}

\section{實驗設定}

訓練的流程包含預訓練和主要訓練。

在預訓練中，我們使用 $D_{Triple}$ 作為輸入資料集。首先我們將每張圖片調整為 $1024 \times 1024$ 的大小以配合後續訓練要求，然後將圖片切為 256 張 $64 \times 64$ 的小圖片餵進模型以 $\alpha = 0.05$ 進行訓練，經過 30 萬個時期 (Epoch) 後得到正規器在主要訓練中的初始權重。
接著我們進行主要訓練，在這個階段我們使用$D_{Train}$作為輸入資料集，把預訓練中得到的正規器和人臉偵測器接在一起做 150 個時期的端對端訓練。
測試時我們使用 $D_{Test}$ 作為輸入資料集，對其四個情境分別進行測試和結果評估。

\section{實驗結果}

以下會展示用我們的方法測試的結果和用基線測試的結果在數據和視覺上的比較。基線是用將 FaceBoxes 的架構以和原論文中同樣的資料集 ($D_{Original}$) 訓練得到的模型直接對 $D_{Test}$ 進行測試，並已事先測試過該模型做在論文中提到的測試資料上結果和原論文結果相似。
數據上的結果比較如表~\ref{table:baseline_compare}，表中數據是我們使用全類平均正確率 (Mean Average Precision) 對偵測結果計算得出的數字，並已經去除部分和本研究無關的結果影響。
\begin{table}[ht]
    \caption{基線和我們的方法之結果比較}
    \centering
    \begin{tabular}{l c c c c}
        \hline
        模型名稱 & 白天進出隧道 & 夜間極暗 & 夜間等紅燈 & 夜間隧道內 \\
        \hline
        基線 (FaceBoxes) & 63.54\% & 31.70\% & 93.35\% & 47.46\% \\
        我們的方法 & 76.25\% & 78.97\% & 97.51\% & 71.66\% \\
        \hline
    \end{tabular}
    \label{table:baseline_compare}
\end{table}

由數據結果可以發現我們的方法得出的結果在環境光較微弱的夜間極暗、夜間隧道內情境下和基線相比分別有 47.27\% 和 24.20\% 的顯著進步，而在白天進出隧道、夜間等紅燈情境下則分別有 12.71\% 和 4.16\% 較小幅的進步。從視覺上的結果 (如圖~\ref{fig:comp_with_base}) 也可看出我們的方法和基線相比能夠偵測出更多曝光不足的人臉，同時兼顧偵測受到正常光線照射下人臉的準確率。

\begin{figure}[t]
\centering
\begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/comp_base1}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/comp_ours1}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/comp_base2}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/comp_ours2}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/comp_base3}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/comp_ours3}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/comp_base4}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/comp_ours4}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/comp_base5}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/comp_ours5}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/comp_base6}
    \caption {基線的測試結果}
\end{subfigure}
\begin{subfigure}[b]{0.45\textwidth}
    \includegraphics[width=\textwidth]{figures/comp_ours6}
    \caption {我們的方法的測試結果}
\end{subfigure}
\caption[我們的方法與基線之視覺結果比較]{比較我們的方法與基線之視覺結果可發現我們的方法能偵測出更多曝光不足的人臉}
\label{fig:comp_with_base}
\end{figure}

\section{消融實驗}

在這一節，我們會探討我們方法中的每個架構與細節是否真的對車內人偵測有效。我們用 $D_{Test}$ 在不同訓練設定下的模型上作實驗，來確認我們方法中的各個步驟都是有效的。首先我們會先探討在訓練時使用模擬曝光不足 / 曝光過度的資料對實驗結果的影響；接著我們會探討在輸入圖片進行偵測前先進行正規化處理對實驗結果的影響；然後我們會探討在預訓練階段使用三圖一組架構對實驗結果的影響；最後我們會探討在主要訓練階段對正規器繼續進行優化對實驗結果的影響。

\subsection{在訓練時使用模擬曝光不足 / 曝光過度的資料}

在我們的方法中，第一個和基線方法不同的地方在於我們訓練時不是使用 $D_{Original}$ 這個收集了正常光照下圖片的資料集，而是使用了將 $D_{Original}$ 模擬曝光不足情境生成的 $D_{Dark}$ 和模擬曝光過度情境生成的 $D_{Bright}$ 合在一起的 $D_{Train}$作為訓練資料集。因此首先我們要先探討這件事是否有效。

由於我們的方法的架構中有正規器，以 $D_{Original}$ 作為訓練資料集意義不大，同時為了去除其他部分對模型造成的影響，最後我們選擇比較\textbf{基線}和\textbf{對照組 A} 這兩個不同訓練設定下的實驗結果如表~\ref{table:data_compare}。
對照組 A 的模型架構只包含人臉偵測器而沒有對輸入圖片進行正規化處理，以 $D_{Train}$ 作為訓練資料集。
兩者差別在於主要訓練階段所使用的資料集不同。基線設定以 $D_{Original}$ 作為訓練資料集；對照組 A 設定則使用了經過演算法模擬曝光不足 / 曝光過度的圖片，以 $D_{Train}$ 作為訓練資料集。

\begin{table}[ht]
    \caption{在訓練時使用模擬曝光不足 / 曝光過度的資料對測試結果的影響}
    \centering
    \begin{tabular}{l c c c c}
        \hline
        設定名稱 & 白天進出隧道 & 夜間極暗 & 夜間等紅燈 & 夜間隧道內 \\
        \hline
        基線 & 63.54\% & 31.70\% & 93.35\% & 47.46\% \\
        對照組 A & 70.97\% & \textbf{63.16\%} & 90.75\% & 62.73\% \\
        \hline
    \end{tabular}
    \label{table:data_compare}
\end{table}

從數據上的結果我們可以得知，對照組 A 設定和基線設定相比在白天進出隧道情境有 7.43\% 的進步，在夜間隧道內情境有 15.27\% 的進步，而在環境光非常微弱的夜間極暗情境更是有 31.46\% 的進步。
我們認為這代表使用較極端光線照射下的圖片作為輸入資料有助於讓偵測器在訓練階段認識更多在不同光線照射下的人臉，使我們在測試階段能夠偵測出更多原本受到光照影響而不認識的人臉。

\subsection{在偵測前進行正規化處理}

在我們的方法中，我們在偵測對輸入圖片進行了正規化處理。接下來我們會探討這一步對實驗結果的影響。
我們比較\textbf{對照組 A}、\textbf{對照組 B}、\textbf{對照組 C}、\textbf{我們的方法}這四個不同訓練設定下的實驗結果如表~\ref{table:normalize_compare}。

對照組 A 如上一小節所述，是以 $D_{Train}$ 作為訓練資料集，整個模型架構只包含人臉偵測器，沒有對輸入圖片進行正規化處理的設定。
對照組 B 在預訓練階段盡可能還原了我們所使用的正規器模型架構 MSR-net~\cite{shen2017msr} 的訓練設定，以 $D_{Dark}$ 作為預訓練的訓練資料集，以用視網膜增強算法對 $D_{Dark}$ 的圖片進行處理後的結果圖片作為基準真相，對正規器進行預訓練。接著在主要訓練階段，我們以 $D_{Train}$ 作為訓練資料集，對正規器和人臉偵測器進行端對端訓練。
對照組 C 在預訓練階段使用了第~\ref{c:method}章圖~\ref{fig:original_pretrain}所提到的架構，以包含了 $D_{Dark}$ 和 $D_{Bright}$ 的 $D_{Train}$ 作為預訓練資料集、$D_{Original}$ 作為基準真相，讓正規器進行監督式學習。接著在主要訓練階段，我們以 $D_{Train}$ 作為訓練資料集，對正規器和人臉偵測器進行端對端訓練。
我們的方法在預訓練階段以包含了$D_{Dark}$、$D_{Bright}$、$D_{Original}$ 的 $D_{Triple}$ 作為預訓練資料集，採用三圖一組的架構 (如圖~\ref{fig:triple_setting})，以迂迴的方式對正規器進行預訓練。接著在主要訓練階段，我們以 $D_{Train}$ 作為訓練資料集，對正規器和人臉偵測器進行端對端訓練。

除了對照組 A 之外的其他設定分別採用了不同架構或設定對正規器進行預訓練，但三者之間共通的是都有對輸入圖片進行正規化處理，僅對照組 A 沒有。

\begin{table}[ht]
    \caption{針對在偵測前進行正規化處理與否之比較}
    \centering
    \begin{tabular}{l c c c c}
        \hline
        設定名稱 & 白天進出隧道 & 夜間極暗 & 夜間等紅燈 & 夜間隧道內 \\
        \hline
        對照組 A & \emph{70.97\%} & \emph{63.16\%} & \emph{90.75\%} & \emph{62.73\%} \\
        \hline
        對照組 B & 74.66\% & 81.21\% &95.42\% & 69.54\% \\
        對照組 C & 73.56\% & 76.02\% & 96.59\% & 68.73\% \\
        我們的方法 & 76.25\% & 78.97\% & 97.51\% & 71.66\% \\
        \hline
    \end{tabular}
    \label{table:normalize_compare}
\end{table}

從數據上的結果我們可以看到，對輸入圖片進行過正規化的設定無一例外都獲得了比對照組 A 更好的結果。
這能夠證明對輸入資料進行正規化處理對人臉偵測有幫助，並且在環境光較微弱的情境下這個影響更加明顯，如在夜間極暗情境下，對照組 B、對照組 C、我們的方法和對照組 A 相比，分別有 18.05\%、12.86\%、15.81\% 的進步。
我們認為這代表正規化處理成功將不同光照下的圖片內容進行調整使其有相似的長相，讓後續的偵測過程更加順利。
特別要注意的是，雖然我們的方法和對照組 B 相比在夜間極暗情境下有 2.24\% 的些微退步，但這個情境的環境光極度微弱，在部分圖片中兩者都只有抓出人臉的一部分，而有些偵測框碰巧跨過了 $IOU >=50\%$ 的門檻。實際上這兩個設定在這個情境下視覺上相差並不大。

\subsection{使用三圖一組架構進行預訓練}

接著我們希望能證明，我們在預訓練階段所使用的三圖一組架構對人臉偵測是有幫助的。為此我們比較\textbf{對照組 C} 和\textbf{我們的方法}這兩個不同訓練設定下的實驗結果如表~\ref{table:triple_compare}。兩個設定的詳細訓練設定在上一小節已經詳述，這裡不再贅述。
兩個設定都會對輸入圖片進行正規化處理，也都有對正規器進行預訓練，預訓練階段所用到的資料集也相同。它們唯一的差別在於預訓練階段所使用的訓練架構。
對照組 C 直接讓正規器進行監督式學習，而我們的方法則使用三圖一組架構迂迴地訓練正規器。

\begin{table}[ht]
    \caption{針對使用三圖一組架構進行預訓練的效果之比較}
    \centering
    \begin{tabular}{l c c c c}
        \hline
        設定名稱 & 白天進出隧道 & 夜間極暗 & 夜間等紅燈 & 夜間隧道內 \\
        \hline
        對照組 C & 73.56\% & 76.02\% & 96.59\% & 68.73\% \\
        我們的方法 & 76.25\% & 78.97\% & 97.51\% & 71.66\% \\
        \hline
    \end{tabular}
    \label{table:triple_compare}
\end{table}

數據上的結果顯示，即使兩個設定都有對正規器進行預訓練，在後續的主要訓練階段也都有進行端對端訓練優化，且在預訓練階段用到的資料集、主要訓練階段使用的資料集和訓練設定等都一致，我們的方法卻有比較好的結果，在四個測試情境下分別進步了 2.69\%、2.95\%、0.92\%、2.87\%。
在第~\ref{c:method}章我們也提過，由於主要訓練階段的需要，我們在預訓練階段所使用的模型架構有較少的參數也較弱，因此對照組 C 的架構無法順利訓練出我們想要的結果。但在我們更動架構後，我們成功獲得了較佳的偵測結果。我們認為這代表預訓練時三圖一組的架構能夠有效降低模型學習如何對圖片進行正規化處理的難度，使訓練結果更容易收斂。

\subsection{在預訓練後對正規器進行端對端訓練優化}

最後我們探討在主要訓練階段對正規器進行端對端訓練優化的必要性。

我們分別比較兩對設定：\textbf{對照組 D} 和\textbf{對照組 B}、\textbf{對照組 E} 和\textbf{我們的方法} 以及\textbf{對照組 A} 這幾個不同訓練設定下的實驗結果如表~\ref{table:optimize_compare}。
對照組 A、對照組 B、我們的方法的詳細設定在前面都已經詳述，這裡不再贅述。
對照組 D 在預訓練階段和對照組 B 完全一致，盡可能還原了 MSR-net 的訓練設定進行預訓練。但在主要訓練階段，我們凍結了正規器的權重，只更新人臉偵測器部分的權重。
對照組 E 在預訓練階段和我們的方法完全一致，使用了三圖一組架構對正規器進行預訓練。但在主要訓練階段，我們凍結了正規器的權重，只更新人臉偵測器部分的權重。
兩對設定有一個共通點，就是都有一個設定 (對照組 D 和對照組 E) 在主要訓練時凍結了正規器的權重，只訓練人臉偵測器本身。對照組 A 在這個比較中則作為沒有用到正規器的對照組。

\begin{table}[ht]
    \caption{不同設定間之結果比較}
    \centering
    \begin{tabular}{l c c c c}
        \hline
        設定名稱 & 白天進出隧道 & 夜間極暗 & 夜間等紅燈 & 夜間隧道內 \\
        \hline
        對照組 A (無正規器) & 70.97\% & 63.16\% & 90.75\% & 62.73\% \\
        \hline
        對照組 D (未優化) & 73.15\% & \emph{60.13\%} & \emph{88.67\%} & 63.88\% \\
        對照組 B (有優化) & 74.66\% & 81.21\% & 95.42\% & 69.54\% \\
        \hline
        對照組 E (未優化) & \emph{22.61\%} & \emph{41.13\%} & \emph{83.31\%} & \emph{30.35\%} \\
        我們的方法 (有優化) & 76.25\% & 78.97\% & 97.51\% & 71.66\% \\
        \hline
    \end{tabular}
    \label{table:optimize_compare}
\end{table}

數據上的結果顯示，光是進行正規器的預訓練是不夠的。如果不進行後續的優化，結果可能反而會比不進行正規化處理還要差。
我們推測這是由於正規器對圖片進行的調整雖然拉近了不同光照下圖片間的距離，卻增加了一些本不應存在的雜訊或使圖片產生了不該有的色偏，使得偵測器無法順利偵測出人臉。但預訓練依然給了正規器一個好的初始權重，讓模型知道這樣調整圖片可以拉近彼此間的距離。
而端對端訓練的意義便在於對正規器做的事情進行調整與優化，使它在拉近圖片間距離的同時顧及偵測器對人臉偵測的需求。

在經過以上的測試後，我們確認了我們的方法中的各個步驟都是有效的。