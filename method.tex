\chapter{方法}
\label{c:method}

我們的方法為了能使在不同光線照射下的輸入資料獲得較好的偵測結果，會在偵測前先對圖片進行正規化，圖一說明了測試時從輸入資料到獲得偵測結果的流程。為了能更好的消除光線對輸入資料造成的影響，我們在訓練上使用了特別設計的訓練流程，主要分為預訓練和主要訓練。

\section{預訓練}

我們做預訓練的對象是負責對圖片進行正規化的正規器，這一步的目的是給正規器一個好的初始權重，以便在後續的主要訓練進行優化。

我們設計了一套特別的訓練架構—三圖一組架構—來訓練正規器 (如圖二)。以下會分別就這套訓練架構中的損失函數、資料和所使用的模型進行說明：

\subsection{損失函數}

我們希望設計出的損失函數能使來自不同光照下的圖片被正規化成相似的結果，以便進行後續的人臉偵測。為了達成這個目標，我們想對同一場景在三個不同光照條件下的圖片進行比較。這個想法是受到了FaceNet 的啟發。它是一篇做人臉辨識的論文，而他們設計的損失函數會使錨點盡量靠近同身份的肯定結果，並使其盡量遠離不同身分的否定結果 (如圖三)，他們透過比較三個點之間距離來修改參數權重的架構啟發了我們。我們的損失函數定義如下：
$$L_{Total} = \alpha L_{Content} + L_{Light}$$
其中$L_{Light}$ 意在使不同光照下的輸入在經過處理後能有盡量一致的長相；而為了使學出來的模型能兼顧保留原圖樣貌和消除光線影響，我們加入了$L_{Content}$ 以保留原圖中的資訊。$\alpha$在此作為一個調整兩個損失函數間取捨的超參數。

我們使用三張一組的圖片來實作上述損失函數的細節，每一組圖片包含了同一場景在曝光正常 (圖4-1)、曝光不足 (圖4-2)、曝光過度 (圖4-3) 這三種情況下的圖片O、D、B。我們將D和B這兩張圖片經過正規器後輸出的兩張圖RD和RB算出兩張圖間的損失函數 $L_3$，此處為了使兩張圖之間的距離越小越好而使用了 L2 損失函數。在此同時，為了不使這兩個結果和原圖相差過大，我們將RD和RB分別和O算出兩個損失函數 $L_1$ 和 $L_2$。這三個損失函數和我們在前面定義的損失函數關係如下：

(Lcontent和Llight 怎麼等於這些損失函數)

\subsection{資料}
由於利用真實資料會有收集上的困難，也較難保證場景中的內容物不變，在此架構中所使用三張一組的資料是透過演算法將原始圖片做調整，模擬出曝光不足和曝光過度這兩個情境下的圖片。以下分別說明兩種情境下的調整：

\subsubsection{模擬曝光不足}
(對圖片的亮度作反珈瑪校正後調暗圖片，再對圖片的亮度作珈瑪校正的公式)
(對圖片的每個畫素加上標準差為N，平均為0的高斯雜訊的公式)

\subsubsection{模擬曝光過度}
(對圖片的亮度作反珈瑪校正後調暗圖片，再對圖片的亮度作珈瑪校正的公式)

\subsection{所使用的模型}
在此架構中我們使用了 MSR-net 來作為正規器的架構。它受到了視網膜增強算法的啟發，是一個能夠對低亮度圖片做影像增強的模型，也就是說它能夠對圖片作局部亮度的調整；它在架構上的設計基於卷積神經網路，能夠接受不同大小的輸入資料；它和其他作影像增強的模型相比較為輕量，方便我們在進行預訓練後將其和偵測器接在一起作端對端的訓練優化。

\section{主要訓練}
在經過預訓練後，我們獲得了一個能夠消除光線對圖片影響的正規器。接下來的主要訓練會將正規器和人臉偵測器接在一起做端對端訓練 (如圖五)。

在主要訓練中，我們的目標是讓來自不同光線照射下的圖片在經過正規化處理後能夠有更多人臉成功被偵測出來。為了模擬不同光線照射下的情境，我們使用了上一節提到的演算法對訓練用的資料做了不同光線照射下的模擬，讓輸入資料包含曝光不足和曝光過度情境下的圖片。
而在模型的挑選上，我們使用了 FaceBoxes 作為主要訓練中人臉偵測器的架構。它是一個基於卷積神經網路的人臉偵測器，透過對卷積層作優化來達到高效率高精確率人臉偵測。由於長遠來說我們希望能夠在車內進行高效率的人臉偵測，因此它是個很好的選擇。
